---
title: "TDP43 concentration dependent analysis"
author: "Matteo Zanovello"
date: "2022-01-10"
output:
---

```{r setup, include = False}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
if (!require("pacman")) {install.packages("pacman")}
if (!requireNamespace("BiocManager", quietly = TRUE)) {install.packages("BiocManager")}
pacman::p_load(tidyverse, data.table, janitor, ggpubr, ggrepel, magrittr, biomaRt, 
               devtools, readxl, DESeq2, edgeR, annotables, rtracklayer, ensembldb,
               PCAtools, clusterProfiler, "org.Hs.eg.db", enrichplot, pcaExplorer, topGO, UpSetR,
               ggtranscript, "TxDb.Hsapiens.UCSC.hg38.knownGene", GenomicRanges)
            
source(here::here('scripts','create_feature_count_table.R'))
source(here::here('scripts','run_standard_deseq.R'))
source(here::here('scripts','make_volcano_plot.R'))
source(here::here('scripts','splicing_volcanoplot.R'))
source(here::here('scripts','trial_graph_concentration.R'))
source(here::here('scripts','run_de_irfinder.R'))
source(here::here('scripts','ggtranscript.R'))
```

this organizes all the data from the many .bam files and creates one data frame you can work with,
then runs the make_deseq_dfs() function and run_standard_deseq() and eventually make graphs
```{r}
featureCounts <- create_feature_count_table("data/feature_count") #change here!!

colnames(featureCounts) <- c("ensgene", 
                           "DOX_0.0125_1", "DOX_0.0125_2", "DOX_0.0125_3",
                           "DOX_0.0187_1", "DOX_0.0187_2", "DOX_0.0187_3",
                           "DOX_0.021", "DOX_0.021_2", "DOX_0.021_3", 
                           "DOX_0.025_1", "DOX_0.025_2", "DOX_0.025_3", 
                           "DOX_0.075_1", "DOX_0.075_2", "DOX_0.075_3",
                           "NT_0_1", "NT_0_2", "NT_0_3", 
                           "gene_name")

pca_table <- featureCounts[,1:19] %>%
    column_to_rownames('ensgene')
annotation <- featureCounts[,c(1,20)] %>%
    column_to_rownames('ensgene')

path_to_meta_you_downloaded <-  "data/metadata.csv" #update this
meta_df <- fread(path_to_meta_you_downloaded)
meta_df <- meta_df %>%
    column_to_rownames('sample') 
meta_df[,1] <- as.factor(meta_df[,1])
meta_df[,2] <- as.factor(meta_df[,2])

pcaExplorer(countmatrix = pca_table, coldata = meta_df, annotation = annotation)


#gene_list <-  c("SYT7", "RSF1", "KCNQ2", "HDGFL2", "AGRN", "ACTL6B", "MYO18A", "MYO1C", "KALRN", "DNM1", "CAMK2B", "ADGRB1", "TARDBP")

grepper <- c("a", "b", "c", "f", "h")
names(grepper) <- c("dox00125", "dox00187", "dox0021", "dox0025", "dox0075")
for (j in grepper) {
my.dds <- run_standard_deseq("data/feature_count", #change here!!
                             base_grep = "NT",
                             contrast_grep = "DOX",  
                             grep_pattern = j,
                             baseName = "Untreated",
                             contrastName = 'TDP43KD')

bbb <- label_significant(my.dds$results_table, gene_list, log2FoldCut = 1.5, log10padj = 5) + annotate("text", x=4, y=-0.25, label=names(j))
plot(bbb)
}
```

splicing volcano and upset plot
```{r}
base <- "noDox"
contrast <- c("dox00125", "dox00187", "dox0021", "dox0025", "dox0075")
datalista <- list()

for (i in contrast) {
  input <- paste(i, "annotated", "junctions", sep = "_")
  input_bc <- paste(base, input, sep = "-")
  input_bc_csv <- paste(input_bc, "csv", sep = ".")
  input_bc_splicing <- fread(file.path(here::here(), "data", "majiq_delta", input_bc_csv))
  names(input_bc_splicing)[13] <- "contrast_mean_psi"

  #a <- splicing_dots_tables_function(input_bc_splicing) + annotate("text", x=0.9, y=0.1, label=i)
  #plot(a)

  datalista[[i]] <- input_bc_splicing
}
big_delta <- rbindlist(datalista, idcol = TRUE)
```


```{r}
big_data_matrix = big_delta %>%
  filter(junc_cat != "annotated") %>%
  mutate(is_a_cryptic = no_dox_mean_psi < 0.05 & contrast_mean_psi >= 0.1) %>%
           #abs(mean_dpsi_per_lsv_junction) > 0.15 & probability_changing > 0.9) %>% # 
  mutate(name = glue::glue("{gene_name}|{junc_cat}|{paste_into_igv_junction}")) %>%
  dplyr::select(name,is_a_cryptic,.id) %>%
  unique() %>%
  filter(is_a_cryptic == T)%>% 
  pivot_wider(values_from = "is_a_cryptic",
              id_cols = "name",
              names_from = ".id",
              values_fill = FALSE, values_fn = sum) %>%
  column_to_rownames('name') %>%
  mutate_all(as.logical)
  
upset(big_data_matrix * 1,
      order.by = "freq", keep.order = TRUE,
      mainbar.y.label = "Junction Intersections", 
      sets.x.label = "Junction Per Level of TDP-43 KD")
```

spaghetti forgetti
```{r}
input_list <- c("no_dox","dox_0125", "dox_0187", "dox_021", "dox_025", "dox_075")
datalist <- list()

for (i in input_list) {
  input <- paste(i, "parsed", sep = "_")
  input_csv <- paste(input, "csv", sep = ".")
  input_splicing <- fread(file.path(here::here(), "data", "majiq_single", input_csv))
  datalist[[i]] <- input_splicing
}
big_data <- rbindlist(datalist, idcol = TRUE)
big_data$.id <- factor(big_data$.id, levels = input_list)

spaghetti_plot(big_data)
spaghetti_plot_normal(big_data)
```

```{r}
postar_bed <- fread("~/Desktop/rbp_bed/human_RBP_binding_sites_sorted.bed", 
                    col.names = c("seqnames", "start", "end", "dataset", "score", "strand", "QC")) ####use TDP only

ensembl <- biomaRt::useEnsembl(biomart = "genes", dataset = "hsapiens_gene_ensembl")
humandb <- biomaRt::getBM(attributes = c("external_gene_name", 
                                         "ensembl_gene_id", "ensembl_transcript_id", "transcript_appris", 
                                         "uniprotswissprot", "uniprotsptrembl", "uniprot_isoform"), 
                          mart = ensembl)
princ <- humandb[which(humandb$transcript_appris == "principal1" |
                       humandb$transcript_appris == "principal2" | 
                       humandb$transcript_appris == "principal3" | 
                       humandb$transcript_appris == "principal4" |
                       humandb$transcript_appris == "principal5"), ]


cds_regions = cdsBy(TxDb.Hsapiens.UCSC.hg38.knownGene, "tx",use.names = TRUE)
cds_regions = unlist(cds_regions)
cds_regions$transcript_id = gsub("\\..*", "", names(cds_regions))

exons_regions = exonsBy(TxDb.Hsapiens.UCSC.hg38.knownGene, "tx",use.names = TRUE)
exons_regions = unlist(exons_regions)
exons_regions$transcript_id = gsub("\\..*", "", names(exons_regions))

file_path = "data/sj_tabs/normalized_annotated/"
suffix = "_normalized_annotated.csv"
psi_files = list.files(file_path,
                       pattern = suffix,
                       full.names = TRUE)
psi_list_full = purrr::map(psi_files,my_clean_reader)
samp_ids = base::tolower(purrr::simplify(purrr::map(psi_files, basename)))
samp_ids = gsub(suffix,"",samp_ids)
##add on the name as an additional column
psi_list_full = purrr::map2(psi_list_full, samp_ids, ~cbind(.x, SampleID = .y))
psi_list_full = purrr::map(psi_list_full,my_name_fixer)
psi_list_full = data.table::rbindlist(psi_list_full)

for (i in contrast) {
 transcript_bind_plot("UNC13A", i)}
```

after running IRFinder, compute DE
```{r}
ir_top_level = "data/irfinder/"
experiment = make_deframe_irfinder(ir_top_level,base_grep = "NT",
                                   contrast_grep = "DOX")$metadata
paths = make_deframe_irfinder(ir_top_level,base_grep = "NT",
                                   contrast_grep = "DOX")$path

for (j in c("0.0125", "0.0187", "0.021", "0.025", "0.075")) {
    experiment <- filter(experiment, grepl(j, SampleNames) | Condition == "control")
    paths <- paths[grepl(j, paths) | grepl("NT", paths)]
}

dds = run_deseq_ir(paths,experiment = experiment)
result = return_formated_results(dds)
result0075 <- result %>% 
    mutate(ir_change = TDPKD -  control)

result_merged <- dplyr::bind_rows(list(result00125, result00187, result0021, result0025, result0075), .id = 'source')
```

GO analysis https://yulab-smu.top/biomedical-knowledge-mining-book/clusterprofiler-go.html
PCAtools package https://bioconductor.org/packages/release/bioc/vignettes/PCAtools/inst/doc/PCAtools.html
```{r}
results <- my.dds$results_table
filtered_res <- filter(results, padj < 0.1 & abs(log2FoldChange) > 2)
## feature 1: numeric vector
geneList <- pull(filtered_res,3)
## feature 2: named vector
names(geneList) = as.character(pull(filtered_res,8))
## feature 3: decreasing order
geneList = sort(geneList, decreasing = TRUE)

ggo <- groupGO(gene = names(geneList),
               OrgDb = org.Hs.eg.db,
               keyType = "SYMBOL",
               ont = "MF",
               level = 3)
cnetplot(ggo)

ego <- enrichGO(gene = names(geneList),
                keyType = "SYMBOL",
                OrgDb = org.Hs.eg.db,
                ont = "BP",
                pAdjustMethod = "BH",
                pvalueCutoff = 0.01,
                qvalueCutoff = 0.05)
goplot(ego)

pgo <- pairwise_termsim(ego)
emapplot(pgo)

gse <- gseGO(geneList     = geneList,
              keyType = "SYMBOL",
              OrgDb        = org.Hs.eg.db,
              ont          = "CC",
              minGSSize    = 50,
              maxGSSize    = 200,
              pvalueCutoff = 0.01,
              verbose      = FALSE)
```